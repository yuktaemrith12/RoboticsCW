
# ğŸ§  AI in Robotics (PDE3802) â€” Office Item Classification

## ğŸ“˜ Overview
This repository contains the **Classification Module** for the *AI in Robotics (PDE3802)* coursework.  
It forms the **Perception** component of the desk-organising robotic arm â€” enabling the robot to **identify and label common office items** from images or a live webcam feed.  

---

## ğŸ§© Project Structure
```

ROBOTICSCW/
â”‚
â”œâ”€â”€ Classification/
â”‚   â”œâ”€â”€ dataset/
â”‚   â”‚   â”œâ”€â”€ Main_Dataset/         # Raw dataset â€“ 10 office item classes
â”‚   â”‚   â”œâ”€â”€ Processed_Dataset/    # Normalised 224Ã—224 RGB images
â”‚   â”‚   â””â”€â”€ Final_Dataset/        # Train / Validation / Test split
â”‚   â”‚
â”‚   â””â”€â”€ scripts/
â”‚       â”œâ”€â”€ _01_normalize.py      # Image resizing and cleaning
â”‚       â”œâ”€â”€ _02_split_script.py   # Train/Val/Test split automation
â”‚       â”œâ”€â”€ _03_evaluate_model.py # Accuracy, F1, confusion matrix
â”‚       â””â”€â”€ Training_Classification_Model.ipynb
â”‚
â”œâ”€â”€ app.py                        # Flask app for upload + webcam classification
â”œâ”€â”€ office_item_classifier.pth    # Trained ResNet-50 weights
â”‚
â”œâ”€â”€ static/
â”‚   â”œâ”€â”€ style.css
â”‚   â””â”€â”€ logo.png
â”‚
â”œâ”€â”€ templates/
â”‚   â””â”€â”€ index.html                # Web interface (two-tab UI)
â”‚
â””â”€â”€ README.md

````

---

## ğŸ§  Recognised Classes
| Class | Example |
|:------|:---------|
| Chair | Office chair |
| Desk Lamp | Table/LED lamp |
| Headphones | Wired/wireless |
| Keyboard | Mechanical/membrane |
| Monitor | LCD/LED monitor |
| Mouse | Wired/wireless |
| Mug | Ceramic/cup |
| Notepad | Notebook |
| Pen | Writing pen |
| Table | Office table |

---

## âš™ï¸ Installation Guide

### 1. Clone Repository
```bash
git clone https://github.com/<your-repo-name>.git
cd ROBOTICSCW
````

### 2. Create Virtual Environment

```bash
python -m venv venv
source venv/bin/activate        # macOS / Linux
venv\Scripts\activate           # Windows
```

### 3. Install Dependencies

```bash
pip install -r requirements.txt
```

### 4. Download Dataset

Because the dataset is too large for GitHub, download it manually:
ğŸ“¦ [Classification Dataset (Google Drive)](https://drive.google.com/file/d/18K4xG9XFKQ2DGNMg43CZ8u7B-xJFcFJg/view?usp=drive_link)

Unzip into:

```
Classification/dataset/Final_Dataset/
    â”œâ”€â”€ train/
    â”œâ”€â”€ validation/
    â””â”€â”€ test/
```

---

## â–¶ï¸ How to Run

### Run the Web Application Locally

1. Ensure the virtual environment is active.
2. Launch the app:

   ```bash
   python app.py
   ```
3. Open your browser at: [http://127.0.0.1:5000](http://127.0.0.1:5000)

You can:

* Upload an image to classify.
* Start your webcam and capture a frame for instant recognition.

**Expected Output:**

* The top predicted class (e.g., â€œMug â€“ 97 %â€) displayed on screen.
* Confidence score + top-3 alternative predictions shown below.

---


## ğŸ“Š Model Details

| Feature                 | Description                              |
| :---------------------- | :--------------------------------------- |
| **Architecture**        | ResNet-50 (Transfer Learning)            |
| **Framework**           | PyTorch                                  |
| **Input Size**          | 224 Ã— 224 RGB                            |
| **Optimizer**           | Adam                                     |
| **Loss Function**       | Cross-Entropy                            |
| **Augmentation**        | Random flip / rotation / brightness      |
| **Split**               | 70 % Train / 15 % Validation / 15 % Test |
| **Validation Accuracy** | â‰ˆ 95 %                                   |
| **Macro F1-Score**      | â‰ˆ 0.91                                   |
| **Saved Weights**       | `office_item_classifier.pth`             |


---

## ğŸ¯ Object Detection (YOLOv8)

In addition to classification, a **YOLOv8-based object detection model** was developed to locate and label multiple desk items in real time.  
This detection system complements the classifier by providing **spatial awareness** â€” helping the robotic arm determine *where* each object is on the desk.

- **Framework:** Ultralytics YOLOv8  
- **Goal:** Real-time detection and bounding box localization of office items  
- **Dataset Source:** Roboflow (pre-annotated YOLO format)  
- **Training:** Fine-tuned pre-trained YOLOv8n model on the same office-item dataset using Google Colab GPU  
- **Augmentation:** Synthetic background variation and rotation for better generalisation  
- **Output:** Custom-trained weights `best.pt` integrated into the Flask web app  
- **Live Detection:** The app displays bounding boxes, labels, and confidence scores from the webcam feed using OpenCV  

This integration enables the robot to perform both **object recognition (ResNet-50)** and **object localisation (YOLOv8)** for a complete desk-organising perception system.


---

## ğŸ§± Dataset Card

* **Name:** Office-Goods Dataset
* **Classes:** 10 office items (see table above)
* **Sources:**  Roboflow 
* **Image Count:** â‰ˆ 21 000 images
* **Pre-processing:** 224Ã—224 px resize, RGB JPEG conversion, LANCZOS filter
* **Split:** Train 70 %  Â·  Validation 15 %  Â·  Test 15 %
* **Purpose:** Classification for robotic perception

---

## ğŸ’¡ Expected Outputs

After running `app.py`, the Flask interface displays:

* **Prediction label** (e.g., â€œPenâ€)
* **Confidence percentage**
* **Optional alternate predictions** if confidence < 95 %
* A preview of the processed image (upload or webcam capture).

When running `_03_evaluate_model.py`:

* Console prints overall accuracy, macro F1, and per-class accuracy.
* A **Seaborn confusion matrix** pops up for visual validation.


---

## ğŸ‘©â€ğŸ’» Team Members

| Name                      | Student ID |
| :------------------------ | :--------- |
| **Yukta R. Emrith**       | M00977987  |
| **Rohaj Gokool Oopadhya** | M00955505  |
| **Kevan Chinapul**        | M00963905  |

---


